{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvihwgPq_sc4"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwtPnaaG_sc4",
        "outputId": "46b20cd6-f755-4c8f-ee6d-d5b5e7927a95"
      },
      "outputs": [],
      "source": [
        "# torch package\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# dataset packagea\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# metrcis\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ETC\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA2DvRS9_sc5"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koQ7yzvk_sc6"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_type:int):\n",
        "        super().__init__()\n",
        "        '''\n",
        "        [(H_in + 2P - K)/S] + 1\n",
        "        '''\n",
        "        # type 16 / 19\n",
        "        self.vgg_type = vgg_type\n",
        "\n",
        "        # (3, 224, 224) -> (64, 112, 112)\n",
        "        self.conv_layer1 = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "\n",
        "        # (64, 112, 112) -> (128, 56, 56)\n",
        "        self.conv_layer2 = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "\n",
        "        # (128, 56, 56) -> (256, 28, 28)\n",
        "        self.conv_layer3 = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "\n",
        "        # (256, 28, 28) -> (512, 14, 14)\n",
        "        self.conv_layer4 = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU())\n",
        "\n",
        "        # (512, 14, 14) -> (512, 7, 7)\n",
        "        self.conv_layer5 = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU())\n",
        "\n",
        "\n",
        "        self.MP_layer = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "\n",
        "        self.add_conv_layer = nn.Sequential(\\\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU())\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\\\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 10)) # 원래는 1000 이지만 데이터셋을 CIFAR10 으로 해서 마지막 출력 노드가 10으로 설정\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.conv_layer3(out)\n",
        "\n",
        "        out = self.conv_layer4(out)\n",
        "        if self.vgg_type == 19:\n",
        "            out = self.add_conv_layer(out)\n",
        "        out = self.MP_layer(out)\n",
        "\n",
        "        out = self.conv_layer5(out)\n",
        "        if self.vgg_type == 19:\n",
        "            out = self.add_conv_layer(out)\n",
        "        out = self.MP_layer(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        vgg16_output = self.fc_layer(out)\n",
        "\n",
        "        return vgg16_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvutF7Iu_sc6"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb7ZniA9_sc6"
      },
      "outputs": [],
      "source": [
        "def train(model, config, train, valid):\n",
        "    train_loss_history = []\n",
        "    valid_loss_history = []\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    for i in range(config.epochs):\n",
        "\n",
        "        train_loss_ = 0\n",
        "        model.train()\n",
        "        with torch.enable_grad():\n",
        "            for feature, label in train:\n",
        "                feature, label = feature.to(config.device), label.to(config.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(feature)\n",
        "                loss = loss_function(outputs, label)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_ += loss.item()\n",
        "\n",
        "        train_loss_ /= config.batch_size\n",
        "        train_loss_history.append(train_loss_)\n",
        "\n",
        "\n",
        "        valid_loss_ = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for feature, label in valid:\n",
        "                feature, label = feature.to(config.device), label.to(config.device)\n",
        "                outputs = model(feature)\n",
        "                loss = loss_function(outputs, label)\n",
        "\n",
        "                valid_loss_ += loss.item()\n",
        "\n",
        "        valid_loss_ /= config.batch_size\n",
        "        valid_loss_history.append(valid_loss_)\n",
        "\n",
        "        clear_output(wait=True) # 주피터 셀 초기화\n",
        "\n",
        "\n",
        "        history_print = []\n",
        "        # if (i+1)%int((config.epochs)*0.1)==0:\n",
        "        log = f\"epoch : {i+1} Loss(train) : {train_loss_history[-1]:.3f}  Loss(valid) : {valid_loss_history[-1]:.3f}\"\n",
        "        history_print.append(log)\n",
        "        for log in history_print[-5:]:\n",
        "            print(log)\n",
        "\n",
        "        plt.plot(train_loss_history, label='Training loss')\n",
        "        plt.plot(valid_loss_history, label='Validation loss')\n",
        "        plt.ylim(0, 5)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*40)\n",
        "    print(\"Training loss: \", train_loss_history[-1])\n",
        "    print(\"Validation loss: \", valid_loss_history[-1])\n",
        "    print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y26Q437H_sc6"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CTkX29q_sc6"
      },
      "outputs": [],
      "source": [
        "def predict_evaluate(model, config, test):\n",
        "    model.eval()\n",
        "    output_list = []\n",
        "    acc = []\n",
        "\n",
        "    y_pred = torch.Tensor()\n",
        "    y_test = torch.Tensor()\n",
        "    with torch.no_grad():\n",
        "        for feature, label in test:\n",
        "            feature, label = feature.to(config.device), label.to(config.device)\n",
        "            outputs = model(feature)\n",
        "            output_list.append(outputs)\n",
        "            outputs = outputs.cpu()\n",
        "            _, outputs = torch.max(outputs, 1)\n",
        "\n",
        "            label = label.cpu()\n",
        "\n",
        "            acc.append(accuracy_score(label, outputs))\n",
        "            y_pred = torch.cat((y_pred, outputs), dim=0)\n",
        "            y_test = torch.cat((y_test, label), dim=0)\n",
        "\n",
        "\n",
        "    print(f\"Accuracy: {(sum(acc)/len(acc)):.3f}\")\n",
        "\n",
        "    return y_test, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqTyXlNk_sc7"
      },
      "source": [
        "# Hyperparameter config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r73cyADt_sc7"
      },
      "outputs": [],
      "source": [
        "class config():\n",
        "    def __init__(self, device, learning_rate=0.001, epochs=100, batch_size = 128):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.device = device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNvdrpOS_sc7"
      },
      "outputs": [],
      "source": [
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA7--nv2_sc7"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDi8J1Ba_sc7",
        "outputId": "e0ade015-2662-4905-abc4-43efad65580f"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "valid_size = len(train_dataset) - train_size\n",
        "\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # 48000\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True) # 12000\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQpGBAJ_sc7"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAU9CuME_sc7"
      },
      "outputs": [],
      "source": [
        "train_config = config(device = device,\n",
        "                    learning_rate = 0.05,\n",
        "                    epochs = 30,\n",
        "                    batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6F4DTN-_sc7"
      },
      "outputs": [],
      "source": [
        "vgg_model = VGG(vgg_type=19).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "gos5bLci_sc7",
        "outputId": "cb5c0566-5155-4267-bcb8-08a3e1349e12"
      },
      "outputs": [],
      "source": [
        "train(vgg_model, train_config, train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_MwMQr7_sc7"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVN9P1gr_sc7"
      },
      "outputs": [],
      "source": [
        "y_test, y_pred = predict_evaluate(vgg_model, train_config, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3meMfOmU_sc8"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV3Cf_2d_sc8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
